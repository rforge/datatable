
FAQ

TO DO : turn into HTML

INTRODUCTION FAQS

1. Why does DT[,5] return 5 ?

Because, by default, unlike with a data.frame the 2nd argument is an \italic{expression} which is evaluated within the scope of DT. 5 evaluates to 5. It is generally bad practice to refer to columns by number rather than name. If someone else comes along and reads your code later, they may have to hunt around to find out which column is number 5. Furthermore, if you, or someone else changes the column ordering of DT higher up in your R program,  you might get bugs if you forget to change all the places in your code which refer to column number 5.
Say column 5 is called “region”,  just do DT[,region] instead. Notice there are no quotes around the column name. This is what we mean by j being evaluated within the scope of the data.table. That scope consists of an environment where the column names are variables.
Having said this, there are some circumstances where refering to a column by number is ok, particular a sequence of columns. In these situations just do DT[,5:10,with=FALSE] or DT[,c(1,4,10),with=FALSE].  See ?”[.data.table” for an explanation of the 'with' argument.
Note that with() has been a base function for a long time.  Thats why we say that data.table builds upon base functionality.  There is nothing new here really, data.table is just making use of with() and building it into the syntax.


2. Why does DT[,”region”] return “region” ?

See answer to 1 above. Try DT[,region] instead. Or if you must then DT[,”region”,with=FALSE].


3. Why does DT[,region] return a vector?  I want a 1-column data.table. There is no drop argument like I'm used to in data.frame.

Try DT[,list(region)] instead.


4. Why does DT[,region,product,sales,currency] not work? I wanted the 4 columns.

The j expression is the 2nd argument.  The correct way to do this is DT[,list(region,product,sales,currency)].


5.I set mycol=“region” but then DT[,mycol] returns “region”.  How do I get it to look up the column name contained in the mycol variable?

This is what we mean when we say the j expression 'sees' objects in the calling scope.  Because 'mycol' does not exist as a column name of DT, R then looked in the calling scope and found mycol there, and returned its value.  This is correct behaviour.  Had mycol been a column name, then that column's data would have been returned.   What you probably meant was DT[,mycol,with=FALSE] which will return the region column's data as you wanted.  Alternatively you could do DT[,eval(mycol)].


6. This is really hard. Whats the point ?

j doesn't have to be just column names. You can put any R expression of column names, directly as the j  e.g. DT[,mean(sales*price-cost)].    The same applies to i.  You have been used to i being row numbers or row names only.  Isn't it nice to just write  DT[sales>1000,sales*price-cost].  What does that mean?  Well it just runs the j expression on the set of rows where the i is true.  The i can be any expression of column names that evaluates to boolean.  You don't even need to return data e.g. DT[sales>1000, plot(profit)].   When we get to compound table joins we will see how i and j can themselves be other data.table queries.  We are going to stretch i and j much further.  But to get there we need you on board first with FAQs 1-5.

7. Ok, I'm starting to see what data.table is about, but why didn't you just enhance data.frame. Why does it have to be a new package?  Isn't this already done by with() and subset() in base ?

As FAQs 1-5 highlight, the j is fundamentally different from data.frame. This is by design. data.frame is a base class and is used throughout base and in many other CRAN packages. Changes like this would simply not be practical since data.frame is so widely used. Even something as simple as DF[,1] would break existing code, see FAQ1.

The real question then is why are the defaults the way they are? Why does it work the way it does?   The simple answer is because the author designed it for his own use, and he wanted it that way. He finds it a more natural, faster way to write code, which also executes more quickly.



8. Why does x[y] just return the columns from x? Shouldn't it return the y columns too?

Good question.  The thinking is that, more often than not, you don't actually want the columns from y which aren't in the key. By default, we try to keep things efficient.  In general we don't want to create memory for the union of things, only to select out a few columns from it in the end. So if you want the computer to do more work, then you need to tell it do so.  You can either do cbind(y,x[y])  or merge(x,y) since a merge method for data.table was added to v1.3.  There are many different ways to do the same thing in data.table.  Its your choice to understand the differences and write good code.
The other thinking is that x[y] is after all a subset of x. The “[“ operator does mean subset,  so by default we thought it was more consistent with base R for x[y] to just return the columns from x.
However it is now apparent that x[y] returning all columns from both tables would be useful,  so an argument inci will be added. We mentioned the merge method for data.table too, but does merge(x,y) mean x[y] or y[x] ?  Those are different things.   Again, this is your choice which syntax you prefer and find clearer.

Finally, although it appears as though x[y] does not return the columns in y,  you can actually use the columns from y in the j expression.  This is what we mean by “join inherited scope”.  Whats the point?   Why not just return the union of all the columns from x and y and then run expressions on that?  Its down to efficiency of code and quicker to program.   When you write  x[y,foo*boo],  data.table automatically inspects the j expression to see which columns it uses.  It will only subset, or group, those columns only.  Memory is only created for the columns the j uses.  Lets say foo is in x, and boo is in y (along with 20 other columns in y).  Isn't x[y,foo*boo] quick to program and quick to run, than a merge step followed by another subset step ?


9. I have 20 columns in data.table x.  Why is x[,sum(V1),by=”...”] so quick?

Several reasons.  i) Only the V1 column is grouped,  the other 19 are ignored because the j expression doesn't use them.  ii) One memory allocation is made for the largest group of V1 only,  then that memory is re-used for the other groups, there is very little garbage to collect  iii)  R is an in memory column store i.e. V1 is contiguous in RAM and page fetches from RAM into L2 are minimised.


10. How can I avoid writing really long j expressions?   You've said I should use the column names, but I've got loads of them.

There is a special .SD object, which stands for Sub Data.  The j expression can use column names as variables, as you know,  but it can also use .SD which refers to the sub data.table as a whole.  So to sum up all your columns its just   DT[,lapply(.SD,sum),by=”...”].   It might seem tricky,  but its fast to write and fast to run.   Notice you don't have to create an anonymous function().  Its very short code too.  See the timing section and comparison to other methods. The .SD object is efficently implemented internally, its more efficient than passing an argument to a function.  Please don't do this though  :   DT[,.SD[,”sales”,with=FALSE],by=”region”].  That works but its very inefficient and inelegant. This is what was intended : DT[,sum(sales),by=”region”] and could be 100's of times faster if DT contains many columns.  No data.table may contain a column called ".SD",  thats why it has a "." at the start as you are unlikely to really want a column called ".SD".



