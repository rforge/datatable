\documentclass[a4paper]{article}

\usepackage[margin=2cm]{geometry}
\usepackage[round]{natbib}
\usepackage{url}
\usepackage{hyperref}

\newcommand{\acronym}[1]{\textsc{#1}}
\newcommand{\class}[1]{\mbox{\textsf{#1}}}
\newcommand{\code}[1]{\mbox{\texttt{#1}}}
\newcommand{\pkg}[1]{{\normalfont\fontseries{b}\selectfont #1}}
\newcommand{\proglang}[1]{\textsf{#1}}
\SweaveOpts{keep.source=TRUE}
%% \VignetteIndexEntry{Introduction to the data.table Package}

\begin{document}
<<echo=FALSE,results=hide>>=
library("data.table")
rm(list=as.character(tables()$NAME))  # for development when we repeatedly run Sweave
@
\title{Introduction to the \pkg{data.table} Package in \proglang{R}}
\author{Matthew Dowle}
\maketitle

\section*{Introduction}

This vignette is aimed at those who are already familiar with \proglang{R}, in
particular creating and using objects of class data.frame. We aim for this quick introduction
to be readable in {\bf10 minutes}, covering the main features in brief. The main features are the 3 numbered
section titles: 1.Keys, 2.Fast Grouping, 3.Fast Merging/Joining. For the context that this document sits please 
briefly check the last section, Further Resources.

data.table is not \emph{automatically} better or faster. The user has to climb a short learning
curve, experiment, and then use the features well. For example this document explains the difference
between a \emph{vector scan} and a \emph{binary search}. Both extract methods are available. If a user
continues to use vector scans though, as they are used to in a data.frame, it will work, but they will 
miss out on the benefits that the package provides.

\section*{Creation}

Recall that we create a \code{data.frame} using the function \code{data.frame()}.
<<>>=
df = data.frame(x=c("b","b","b","a","a"),v=rnorm(5))
df
@
We create a \code{data.table} in exactly the same way.
<<>>=
dt = data.table(x=c("b","b","b","a","a"),v=rnorm(5))
dt
@
Observe that a data.table prints the row numbers slightly differently. There is nothing
significant about that.
We can also convert existing data.frame objects to data.table.
<<>>=
cars = data.table(cars)
head(cars)
@
We have just created two data.tables: dt and cars. It is often useful to see a list of all our
data.tables in memory.
<<>>=
tables()
@

The MB column is useful to quickly assess memory use and to spot if any redundant tables can be
removed to free up memory. Just like data.frame's, data.table's must fit inside RAM. 

Some users regularly work with 20 or more tables in memory, rather like a database. The result of tables()
is itself a data.table, returned silently, so that tables() can be used in programs. tables() is unrelated to 
the base function table().

You may have noticed the empty column KEY. This is the subject of the next section, the first of the 3 main features
of the package.


\section*{1. Keys}

Lets start by considering data.frame, specifically ''rownames''. Or in English ''row names''. That is, the
multiple names belonging to the single row.  The multiple names belonging
to the single row?  No, that is not what we are used to in a data.frame. We know that each row has at
most one name, but never \emph{more} than one name.  A person has at least two names, a first name and a second
name. That is useful to organise a phone directory of people. But each row in a data.frame can only have one name.

A \emph{key} is one or more columns of rownames. These columns may be integer, factor or other classes, not
just character. Furthermore, the rows are sorted by the key. Therefore a data.table can have at most one key,
because it cannot be sorted in more than one way.

Uniqueness is not enforced i.e. duplicate key values are allowed. Since
the rows are sorted by the key, any duplicates in the key will appear consecutively.

Lets remind ourselves of our tables :
<<>>=
tables()
dt
@

No keys have been set yet.  We \emph{can} use data.frame syntax without a key.

<<>>=
dt[2,]
dt[ dt$x == "b", ]
@

But since there are no rownames the following does not work.
<<>>=
cat(try(dt["b",]))
@

The error message tells us we need to use setkey().

<<>>=
setkey(dt,x)
dt
@

Notice that the rows in dt have been re-ordered by x. The two ''a'' rows have moved to the top.
We can confirm that dt does indeed have a key using haskey(), key(),
attributes(), or just running tables().

<<>>=
tables()
@

Now we are sure that dt has a key, lets try again.

<<>>=
dt["b",]
@

Since there are duplicates in this key (i.e. repeated values of ''b'') the subset returns the first row in that group, by default. The
\code{mult} argument (short for \emph{multiple}) controls this.

<<>>=
dt["b",mult="first"]
dt["b",mult="last"]
dt["b",mult="all"]
@

Lets now create a data.table with a 2 column key. We can do this in one step this time by using the key argument of data.table(). 
We will also make it large enough to demonstrate the difference between a vector scan and a binary search.
<<>>=
n=1e6
dt2 = data.table(x=sample(LETTERS,n,replace=TRUE),
                 y=sample(LETTERS,n,replace=TRUE),
                 v=rnorm(n),
                 key="x,y")
head(dt2)
tables()
@

TO DO- explain difference between vector scan and binary search. Advise to unlearn ==.

First section was to do with i. Second section to do with j.

\section*{2. Fast grouping}

So far we have dealt with the first argument inside []. The first is call i. The second is called j and may be
one or more expressions of column names as if the column names were variables.

When we supply a j expression and a 'by' list of expressions, the j expression is repeated for each group defined
by the 'by'.

subsection : Scope

Think of the subset as an environment where all the column names are
variables. When a variable is used in the j expression, it is looked for in the following order :
\begin{enumerate}
\item The scope of the subset i.e. the column names
\item The scope of the calling frame e.g. the line that appears before the data.table query
\item TO CHECK. Does it ripple up or go straight to .GlobalEnv?
\item The global environment
\end{enumerate}

This is ''lexical scoping'' explained by \href{http://cran.r-project.org/doc/FAQ/R-FAQ.html#Lexical-scoping}{R FAQ 3.3.1}


TO DO - examples.

\section*{3. Fast joining/merging}

x[y] is a join between x and y,  a subset of x defined by y
merge(x,y) is the same but contains the union of columns.  When merge is passed data.table's, it operates much
faster than base merge on data.frame's.

TO DO - examples.

\section*{Other resources}

This was a quick start guide. Further resources include :
\begin{itemize}
\item The help page describes each and every argument \code{?"[.data.table"}
\item The FAQs deal with distinct topics in an easy to digest manner
\item The performance tests are more complex real world examples
\item test.data.table contains over 100 low level tests of the features.
\item Presentations
\item YouTube Demo
\item R-Forge commit logs: \url{http://lists.r-forge.r-project.org/pipermail/datatable-commits/}
\item Website: \url{http://datatable.r-forge.r-project.org/}
\item Mailing list : \href{mailto:datatable-help@lists.r-forge.r-project.org}{datatable-help@lists.r-forge.r-project.org}

\end{itemize}

\end{document}


